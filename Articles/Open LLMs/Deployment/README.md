# Effective Deployment Strategies for Language Models

| Deployment Tools | Description | Resource |
|------ | ---------- | :--------- |
| SkyPilot | Run LLMs and batch jobs on any cloud. Get maximum cost savings, highest GPU availability, and managed execution -- all with a simple interface. | [ðŸ”—](https://github.com/skypilot-org/skypilot)|
|vLLM | A high-throughput and memory-efficient inference and serving engine for LLMs | [ðŸ”—](https://github.com/vllm-project/vllm)|
|Text Generation Inference | A Rust, Python and gRPC server for text generation inference. Used in production at HuggingFace to power LLMs api-inference widgets. | [ðŸ”—](https://github.com/huggingface/text-generation-inference)|
| Haystack | an open-source NLP framework that allows you to use LLMs and transformer-based models from Hugging Face, OpenAI and Cohere to interact with your own data. | [ðŸ”—](https://haystack.deepset.ai/)|
| Sidekick |  Data integration platform for LLMs. | [ðŸ”—](https://github.com/psychic-api/psychic)|
| LangChain |  Building applications with LLMs through composability | [ðŸ”—](https://github.com/hwchase17/langchain)|
| wechat-chatgpt | Use ChatGPT On Wechat via wechaty | [ðŸ”—](https://github.com/fuergaosi233/wechat-chatgpt)|
| promptfoo | Test your prompts. Evaluate and compare LLM outputs, catch regressions, and improve prompt quality. | [ðŸ”—](https://github.com/promptfoo/promptfoo)|
| Agenta | Easily build, version, evaluate and deploy your LLM-powered apps | [ðŸ”—](https://github.com/agenta-ai/agenta)|
| LiteChain | Build robust LLM applications with true composability | [ðŸ”—](https://github.com/rogeriochaves/langstream)|
| magentic | Seamlessly integrate LLMs as Python functions | [ðŸ”—](https://github.com/jackmpcollins/magentic)|  
| Serge | A web interface for chatting with Alpaca through llama.cpp. Fully dockerized, with an easy to use API. | [ðŸ”—](https://github.com/serge-chat/serge#serge---llama-made-easy-)|
| Langroid | Harness LLMs with Multi-Agent Programming | [ðŸ”—](https://github.com/langroid/langroid)|
| Embedchain | Framework to create ChatGPT like bots over your dataset. | [ðŸ”—](https://github.com/embedchain/embedchain) | 
| FastChat | A distributed multi-model LLM serving system with web UI and OpenAI-compatible RESTful APIs. | [ðŸ”—](https://github.com/lm-sys/FastChat) |
| Swiss Army Llama| Comprehensive set of tools for working with local LLMs for various tasks. | [ðŸ”—](https://github.com/Dicklesworthstone/swiss_army_llama)|
| CometLLM | A 100% opensource LLMOps platform to log, manage, and visualize your LLM prompts and chains. Track prompt templates, prompt variables, prompt duration, token usage, and other metadata. Score prompt outputs and visualize chat history all within a single UI. | [ðŸ”—](https://github.com/comet-ml/comet-llm)|
| IntelliServer | simplifies the evaluation of LLMs by providing a unified microservice to access and test multiple AI models. | [ðŸ”—](https://github.com/intelligentnode/IntelliServer)|
| OpenLLM | Fine-tune, serve, deploy, and monitor any open-source LLMs in production. Used in production at [BentoML](https://bentoml.com/) for LLMs-based applications. | [ðŸ”—](https://github.com/intelligentnode/IntelliServer)|
| DeepSpeed-Mii | MII makes low-latency and high-throughput inference, similar to vLLM powered by DeepSpeed. | [ðŸ”—](https://github.com/microsoft/DeepSpeed-MII) |
| Text-Embeddings-Inference | Inference for text-embeddings in Rust, HFOIL Licence | [ðŸ”—](https://github.com/huggingface/text-embeddings-inference) |
| infinity | Inference for text-embeddings in Python | [ðŸ”—](https://github.com/michaelfeil/infinity)|
| TensorRT-LLM |  Nvidia Framework for LLM Inference | [ðŸ”—](https://github.com/NVIDIA/TensorRT-LLM)|
| Flash-Attention  | A method designed to enhance the efficiency of Transformer models | [ðŸ”—](https://github.com/Dao-AILab/flash-attention)|
| Langchain-Chatchat  | Formerly langchain-ChatGLM, local knowledge based LLM (like ChatGLM) QA app with langchain. | [ðŸ”—](https://github.com/chatchat-space/Langchain-Chatchat)|
| Search with Lepton | Build your own conversational search engine using less than 500 lines of code by [LeptonAI](https://github.com/leptonai).| [ðŸ”—](https://github.com/leptonai/search_with_lepton)|