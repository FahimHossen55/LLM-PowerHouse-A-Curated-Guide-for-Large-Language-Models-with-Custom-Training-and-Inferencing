# Open Source LLM Space for Research Use
| Language Model | Description | Link |
|------ | ---------- | :---------: |
| Baize | Baize is an open-source chat model trained with [LoRA](https://github.com/microsoft/LoRA). It uses 100k dialogs generated by letting ChatGPT chat with itself.| [ðŸ”—](https://github.com/project-baize/baize-chatbot)|
| Koala | A Dialogue Model for Academic Research| [ðŸ”—](https://github.com/project-baize/baize-chatbot)|
| Dalai | The simplest way to run LLaMA on your local machine | [ðŸ”—](https://github.com/cocktailpeanut/dalai)|
| LLaMA | A foundational, 65-billion-parameter large language model. [LLaMA.cpp](https://github.com/ggerganov/llama.cpp) [Lit-LLaMA](https://github.com/Lightning-AI/lit-llama) | [ðŸ”—](https://github.com/cocktailpeanut/dalai)|
| ColossalChat |  LLM trained with RLHF powered by Colossal-AI | [ðŸ”—](https://github.com/cocktailpeanut/dalai) | 
| Vicuna | An Open-Source Chatbot Impressing GPT-4 with 90% ChatGPT Quality. | [ðŸ”—](https://github.com/lm-sys/FastChat)|
| Dolly | A cheap-to-build LLM that exhibits a surprising degree of the instruction following capabilities exhibited by ChatGPT | [ðŸ”—](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html) | 
| GPT4All | Demo, data, and code to train open-source assistant-style large language model based on GPT-J and LLaMa | [ðŸ”—](https://github.com/nomic-ai/gpt4all) | 
| Alpaca | A model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. [Alpaca.cpp](https://github.com/antimatter15/alpaca.cpp) [Alpaca-LoRA](https://github.com/tloen/alpaca-lora) | [ðŸ”—](https://github.com/nomic-ai/gpt4all) | 
